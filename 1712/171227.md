### Title
WaveNet: A Generative Model for Raw Audio

### Authors
Google DeepMind

### link
[Download link](https://arxiv.org/pdf/1609.03499.pdf)

### Contents
- Dilated Causal Convolution을 이용한 다음 waveform 모델링
- causal convolution은 뭐냐?
    - 일반적인 window size n인 convolution filter는 자료 주변으로 n/2개씩 자료가 포함되도록 되어 있음
    - 근데 소리 자료는 이후에 나올 값을 포함시킨다는게 말이 안됨
    - ordering이 아주 중요한 소요
    - 논문의 표현을 빌리자면 the prediction at timestep t cannot depend on any of the future timesteps
    - 이전 시점의 자료만 쓰도록 하는게 causal convolution
    - masked convolution과 같은거.. 이미지 처리에서 구현 시에는 masking matrix 만들어서(t시점 전에는 1 이후에는 0인 matrix) 자료에 곱해주면 됨
- dilated convolution은 그럼 뭐임?
    - convolution with holes
    - 자료를 몇 step식 뛰어 넘어서 filter size보다 더 넓은 범위 커버할 수 있도록 만들어진 convolution
    - 더 넓은 범위의 자료를 효과적으로 다룰 수 있도록 해줌
- softmax distribution
    - ![image](../image/171227_1.png)
    - conditional distribution을 어떻게 나타낼까? 기존에는 gaussian scale mixture 등등을 사용했었지만 그냥 softmax distribution으로 나타내는게 좋더라
    - 16bit 소리 -> 65536 probs per timestep to model
    -  µ-law companding transformation을 이용하여 변형
- gated activation unit 사용
    - ![image](../image/171227_3.png)
    - layer의 activation 계산되는 내부에서 z는 다음과 같은 gated activation으로 계산
    - ![image](../image/171227_4.png)
    - x는 input, W_f,k는 filter, W_g,k는 gate, h는 text input과 같은 다른 변수
