### Title
Understanding Grounded Language Learning Agents

### Authors
Deepmind

### link
[Download link](https://arxiv.org/pdf/1710.09867.pdf)

### Contents
1. Introduction
    - 요즘 situated language learning agents에 대한 관심 많음
    - 언어를 읽고 그 안에 담긴 상황을 이해해서 주변 환경에 맞게 행동하기
    - 어떻게 이 agent들이 학습하나? 여러 연구들을 통해서 한 번 이해해보려고 함
    - 발견
        - Shape / color biases: 이건 이전에 다른 논문에 한 번 나왔던 것 같은데.. 원래 발달심리에서 보면 아이들보고 비슷한 물건끼리 묶어보라고 하면 비슷한 색깔로 묶기보다는 비슷한 모양별로 묶는 경향이 있음, categorization을 사람이 하는 방식으로 하려면 shape words를 더 많이 보여주는게 좋다는건 이런 관점에서 잘 이해가 되는 부분..
        - The problem of learning negation: negation 문장을 학습하는데 데이터가 적으면 이상하게 한다고? 어떻게 하는지는 읽어봐야 할 것 같음..
        - curriculum effects for vocabulary growth: 단어 학습할 때 처음에는 적은 수의 단어만 늘려가다가 나중에 확 늘리면... 학습이 좋더라
        - semantic processing and representation differences: 음.. 이건 뭔소리지?

1. 일단 실험 상황 설명
    - agent한테 visual input(continuous pixel tensor), symbolic textual instruction(word-level) 줌
    - agent는 앞뒤 움직임, 돌기 등등 행동 가능
    - simulation

1. A situated Language Learning Agent
    - 두 정보를 처리할 수 있는 neural network module
        - sequential symbolic input은 recurrent network
        - visual input은 convolutional network
    - 매 시점 t마다 두 모듈에서 나온 정보를 mixing module에 넣고 policy network A에 넣어서 행동과 value 예측

1. Experiments
    - word learning biases
        - agent 데려다 놓고 학습시킴, two object, one instruction word, 해당 word가 나타내는 속성을 가지고 있는 걸 선택하면 positive reward
        - 이걸 color terms, shape terms, ambiguous terms에 대해 했엉
        - ambiguous terms는 특정 사물과 1:1 matching되는 단어셋임
        - 예를 들어 dax가 black pencil이고 나중에 dax를 주고 blue pencil, black fork중에 고르게 해서 확률이 5:5가 아니라면 shape/color 어느 한 쪽으로 bias가 있는 것으로 보는거지
        - 결과를 보면 color bias를 대체로 보임.. Ritter et al(imagenet에서 shape bias 이야기한 그 논문) 결과하고도 비교해서 생각해볼 수 있는데 cnn structure가 shape bias를 보이는 걸수도 있고.. 아니면 여기 자극이 너무 simple해서 그럴 수도 있다고 난 생각함, 아무래도 색깔의 차이보다는 모양의 차이가 덜 구분된다고 해야하나.. 뭐 그런 느낌이 없지는 않은 것 같은디
    - The problem of learning negation
        - tell me a joke that is <strong>not</strong> offensive
        - 자연어 처리는 이런 부정 표현 처리하는게 참 힘들어..
        - not w가 단순 w를 안하라는것이 아닌 "w가 아닌 나머지 원소"임을 나타낸다는 것을 알아야 generalization이 가능.. 실제 결과를 보면 그게 쉽지는 않은 것 같아 보임
        - 학습에서 집합의 원소수를 늘리는게 generalization에 도움을 줬음.. 아마도 overfitting이 되지 않는 어떤 특정한 방식을 찾은게 아닐까? 6개에 대해 not w의 패턴 그 자체를 외우는건 쉽지만 20개에 대해 다 외워버리는건 쉽지 않을테니.. 이건 정말 무슨 일이 일어났을지 모르겠당ㅋㅋㅋ
    - curriculum learning
        - 실제 neural network도 복잡한 자극보다는 쉽고 구분하기 좋은 자료를 처음에 학습시키는게 도움이 됨
        - text자료는 그런 면에서 이런게 좀 어려움.. 어떤게 단순한 자료인거?
        - 아예 자료의 subset만 주는 방식으로 점진적 학습 구현
        - 저런식으로 자료 주는게 아주 효과적이었음
    - processing and representation differences
        - 첫 번째 실험은 어떤 class의 단어(color, shape, pattern, size, shade, superordinate category)가 가장 학습이 빠를까?
        - 자연적인 상황에서는 40개 shape 학습하는게 12개 color 학습하는 것보다 더 빨랐음
            - 근데 적어도 rgb 학습은 초반에 엄청 빨리 이루어지지 않을까?
        - 그 다음 layerwise attention으로 shape / color word 학습시킬 때에 visual attention이 어떤 layer에서 주로 처리되고 input에 어떤 feature에 초점을 맞추는지 분석해봄, 결과는 뭐.. 모양일 때에는 좀 더 high level feature에 영향을 많이 받고 color일 때에는 low level layer에서 처리된 feature에 영향을 많이 받더라.. 생각하는 것과 비슷하네.. 뇌의 실제 이미지 처리 경로를 생각해봐도 꽤나 일리있는 것 같음
        - 