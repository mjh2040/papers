### Title
Deep Text Classification Can Be Fooled

### Authors
Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, Wenchang Shi

### link
[Download link](https://arxiv.org/pdf/1704.08006.pdf)


### Contents
1. Introduction
    - 이미지, 오디오 연구에서 인공신경망 기반 모형들이 adversarial attack에 약하다는 연구가 계속 나오고 있음(Goodfellow et al. 2015; Kereliuk et
al. 2015)
    - 이런 자극들은 사람이 보기에는 여전히 충분히 구분이 가능한 이미지이지만 모형에서는 오류율이 크게 늘어남
    - adversarial sample 만들 때에 애초에 loss에 대해서 각 변수들 미분해가지고 변화가 큰 것들만 바꾸는 방식을 취하고 있으니 너무나도 당연한 결과
    - potential adversarial attack을 방지하는 것이 아주 중요한 과제임에도 불구하고 text에 대해서는 연구가 적음
    - 문제는 각 pixel에서는 continuous data인 image, audio와는 다르게 text는 discrete data라는 점
    - 본질적으로 접근 방식을 다르게 가져가야 함 -> 사람이 봤을 때에는 의미가 유지되어야 한다는 점이 adversarial attack의 중요한 점
    - 두 가지 고려해야 할 사항
        1. utility-preserving: 변형이 되더라도 본문 내용이 이해가 되어야 함
        1. imperceptible: 사람이 쉽게 알아차릴 수 없어야 함
    - 자기들은 3가지 방법을 고안했다고 함: insertion, modification, removal
    
1. Target Model and Dataset
    - model은 (Zhang et al. 2015)에서 쓴 것과 같은 character-based cnn model
    - dataset은 DBpedia 데이터셋, 학습 56만건

1. Methodology
    - (Ianfellow et al 2015)처럼 character를 pixel로 바꿔서 gradient를 주면 의미가 많이 망가짐
    - 자기들은 단어나 문장을 집어넣는 방식이나 빼는 방식으로 해보겠다
    - <font color="red">개인적인 의견: 나는 이 방법은 사람들에게서 자연스럽게 나올 수 있는 perturbation은 아니라고 봄, 필요한 문장이나 단어를 빼먹는 경우는 사람이 글을 작성할 때에 그렇게 흔하게 일어나는 일은 아니지 않나? 생각해보니 사람들이 워낙 글을 못써서 그럴 수 있을지도 모르겠네ㅋㅋㅋ</font>
    - Insertion Strategy: hot character(cost gradient가 큰 character)를 구하고 이게 많이 들어간 phrase를 찾음, 이렇게 찾아낸 phrase set에서 임의로 글에다가 몇 개 집어넣는게 insertion strategy
        - <font color="red">개인적인 의견: 나는 이 방법은 사람들에게서 자연스럽게 나올 수 있는 perturbation은 아니라고 봄, 너무 맥락없이 단어들이 들어가는 경우들이 많이 생길 것 같은데...</font>
    - Modifiation Strategy: 문서 내에서 hot sample phrase를 찾음(방법은 위와 동일), modification은 2가지 방법이 있음
        1. choose the common misspellings of it from related corpora to replace it
        2. alter some of its characters to ones in similar visual appearance
        - <font color="red">개인적인 의견: 이게 내가 생각하는거랑 유사함, 여기서는 두 가지만 사용했는데 이 방법을 더 늘려보는게 좋지 않을까?</font>
    - Removal Strategy: hot phrase 찾아서 지우기
    
1. Result
    - classification 정확도는 많이 떨어짐
    - 학생 23명에게 20개씩 문서주고 절반은 perturbation이 있는거라고 한 다음 classification하게 해봤고 수정된 부분이 있는 것 같으면 표시하라고 했음. 사람의 분류 정확도는 model의 정확도보다 훨씬 높음(model: 84.7, human: 94.2%)
    - 주작된 곳 찾는 정확도는 5.0%밖에 안됨, 티안나게 했다는 증거?
