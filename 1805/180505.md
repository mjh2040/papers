### Title
On the Information Bottleneck Theory of Deep Learning

### Authors


### link
[Download link](https://openreview.net/pdf?id=ry_WPG-A-)

### Contents
- 기존 Shwartz-Ziv & Tishby(2017)에서 neural network를 information theory 관점에서 설명했던 것이 있었음
    - neural network는 두 부분으로 나눠볼 수 있는데
        - I(T ; X): mutual information between 
        - I(Y ; T): mutual information between hidden features and labels
        - neural network 학습 과정을 보면 I(Y ; T)가 올라가는 drift phase와 I(T;X)가 감소하는 diffusion phase가 있다는 것을 simulation을 통해서 보여주고 왜 neural network가 generalization이 잘되는지.. 기타등등에 대해 말했던 논문임
- 이 논문에서는 위에서 관찰되었던 현상은 특수한 경우에 한정되는 것이며 information bottleneck theory가 모든 경우에 대해 다 맞는건 아니라는 이야기를 하고 있음

- 첫 번째로 compression은 double-saturating activation을 사용한 경우에만 일어난다는 것을 보여줌
    - tanh은 large weight에 대해 activation이 양쪽 끝(-1, 1)로 나뉘게 되니까 input 분포가 더 단순한 분포로 collapsing이 일어나고 그래서 compression이 일어난다고 이야기 함
    - 반면 ReLU같은 경우는 saturating이 없고 한 쪽은 0으로, 나머지는 input과 동일한 분포를 보이니까 단순하게 변하지는 않음
    
- 그 다음 위에서 이야기했던 두 단계 dynamics에 대해서도 이야기함
    - 첫 단계는 loss가 줄어드는 부분, 두 번째는 compression이 일어나는 부분
    - 여기서는 linear teacher network의 결과물을 학습하는 deep linear network를 가지고 이를 테스트해봄
    - 여기서는 전혀 compression이 일어나지 않음. 오히려 반대 방향으로 변험(I(T;X)가 증가하는 방향으로)

- 그리고 stochasticity가 compression에 중요하다는 이야기를 했었는데
    - 이 논문에서는 full batch를 가지고도 실험해봤는데 여전히 동일한 현상(tanh는 양쪽 다 compression / ReLU는 아무 변화 없음)

- 그리고 여기서는 이상한 input(teacher network에서 특정 input에 대해서는 weight를 다 0으로 바꿔벼려서 noise와 같은 feature) 이를 학습하게 했더니
    - 당연히 모형 전체 성능이 좋으려면 저런건 무시해버려야 하고
    - 학습 과정에서 보니 저런 것들만 I(T;X)가 감소하더라...
    - 나머지 의미있는 것에 대해서는 그렇지 않았음
    
- 그래서 이런 여러 결과들로 기존 Information Bottleneck Theory의 결과에 대해 의구심을 제기하고...
- 원 논문 저자가 이에 대해 openreview에 반박한 게 있는데 살펴보면 좋음
- [link](https://openreview.net/forum?id=ry_WPG-A-)