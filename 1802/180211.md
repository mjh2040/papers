### Title
byte level recursive convolutional autoencoder for text

### Authors


### link
[Download link](https://arxiv.org/pdf/1802.01817.pdf)

### Contents
- text를 4byte로 encoding
- 각 byte마다 256 dim vector로
- 각 char byte reshaping은 아래와 같이
![image](../images/180211.png)
- 그런 다음에는 temporal convolution 이용해서 길이와 상관없이 하나의 latent hidden vector 얻는게 다임
- 이 논문의 특별한 점이라고 한다면 character 대신 byte를 사용했다는거
- character를 쓰려고 해도 one hot vector의 dimension이 엄청 커지는데 byte단위로 하면 그럴 걱정은 없음
- 근데 이건 representational power가 엄청 약할 것 같은데.. 이게 된다고?
- 솔직히 말하면 너무 믿기가 힘듦..
- lecun이 중국가가지고 어떻게 중국어 다룰지 고민하다가 byte로 해버리자!! 이렇게 된 것 같은데 나도 한 번 해봐야 할 것 같음
- 우선은 간단히 classification 문제부터 만들어서 해보고 text generation쪽도 한 번 해봐야지..