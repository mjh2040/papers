### Title
Six Challenges for Neural Machine Translation

### Authors
Philipp Koehn, Rebecca Knowles

### link
[Download link](http://aclweb.org/anthology/W/W17/W17-3204.pdf)

### Contents
1. Introduction
    - 자기네들이 생각하는 6가지(7번째 말하면서 black-box 이야기하기는 했지만 여튼) NMT가 극복해야 할 문제점
        1. show low quality out of domain
        1. steeper learning curve with respect to the amount of data
        1. show weakness in translating row freq words
        1. have lower translation quality on very long sentences
        1. unpredictable word alignment model
        1. beam search decoding
    - 위의 문제들에 대해 empirical experiment 해보겠다
    
1. Experiment Setup
    - SMT는 Moses 사용
    - corpus는 뭐 이것저것 5개 dataset 사용했음
    - NMT는 Nematus사용.. 거의 최신 모형이니까 성능은 별 문제없을 듯
    
1. Challenges
    1. Domain Mismatch
        - Out of Domain sentence가 들어왔을 때에 NMT가 SMT에 비해 훨씬 안좋았음, 근데 사실 어느쪽도 다 안좋아져서 그냥 총체적 문제라고 봐야 할 듯
        - General model만들고 domain specific dataset만 재학습시키는 domain adaptation방법을 보통 그래서 많이 사용하는데.. 
        - 일종의 style문제라고 보이는데 사실 번역에 있어서는 이게 practically 문제가 되는 상황 자체는 그리 안많은거 아닐까
    1. Amount of Training Data
        - 획실히 데이터가 적었을 때에 SMT보다 성능이 확 떨어짐, 근데 또 데이터 많으면 별 문제는 아님
        - 결국 데이터 문제
    1. Rare Words
        - dataset에 안등장하는 단어가 있을 가능성 있음
        - subword vocab을 사용하는 경우(byte-pair encoding) 문제는 좀 덜함
        - 생각보다는 잘되는데 한국어는 어떨까?
        - byte-pair로 쪼갰을 때에 stem이 안변하면 좋은데 한국어같은 경우는 stem도 종종 변하는 경우가 있어서 그게 좀 문제가 될 수 있을 것 같음, 그래서 형태소 분석을 하는 편이 더 나을지도 모를 것 같다는 생각이..
    1. Long sentences
        - 60token까지는 NMT랑 SMT랑 비슷하고 NMT는 그것보다 길이가 길어지면 성능 확 나빠짐
        - rnn model의 한계일지도 모르겠는데.. 예전에 구글이 long sentence chatbot 만들 때 했던 것처럼 해보는건 어떨까 생각이 들기도 함 (Generating Long and Diverse Responses with Neural Conversation Models)
    1. word alignment
        - 이거는 우려와는 달리 크게 문제는 없는 것 같음. attention mechanism이 잘 작동하는 것 같은데..
    1. beam search
        - 최적의 beam size넘어가거나 부족하면 결과값이 좋지 않음, beam size 키우는 게 항상 능사는 아님
        - http://aclweb.org/anthology/W/W17/W17-3207.pdf
        - https://arxiv.org/abs/1702.02429
        - 이런걸 읽어보자, 요새는 beam search도 dynamic하게 접근하려고 많이 노력하는 것 같음