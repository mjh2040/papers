### Title
Character-level Convolutional Networks for Text classification

### Authors
Xiang Zhang, Junbo Zhao, Yann LeCun

### link
[Download link](https://arxiv.org/pdf/1509.01626.pdf)


### Contents

1. Introduction
    - temporal convolutional neural network 사용 -> RGB 등 여러 층으로 나뉜 이미지랑 다르게 텍스트는 한 층밖에 없음

1. Character-level Convolutional Networks
    1. Key Modules
        - temporal kernel
    1. character quantization
        - one-hot encoding, 최대 m개의 character(연구에서는 70개)만 활용
        - fixed length l0
        - 글이 그 이상 되는건 잘라버리고 빈칸 및 m개에 속하지 않는 character들은 영벡터로 처리함
    1. Data Augmentation using Thesaurus
        - deeplearning 성능 올리기 위해서는 비슷한 자료 많이 만들어서 generalization 할 수 있도록 하는게 중요
        - 사람한테 rephrase하게하기? 불가능
        - libreoffice에 있는 시소러스 기능으로(wordnet 이용한거임) 단어 갈아치울거 결정함
        - 몇 개나 갈아치울지는 geometric distribution에서 뽑기
1. Comparison Models
    1. Traditional Methods
        - tf-idf 기반
    1. Deep learning
        - one hot encoding말고 pretrained word2vec embedding 사용
        - lstm
1. Results
    - 결과는 별거 없음, cnn이 다른 최신 기법들과 맞먹는 성능 가지고 있다는거
    - 
        
        
1. 내 논문의 아이디어
- 챗봇을 만드는 데에 있어서 RNN 많이 사용되긴 하는데 단순 QA agent 만드는데에는 여전히 classification 이용
- dnn, rnn, cnn 등 이용가능
- adversarial attack에 특히 취약하다는 연구가 있음[link](https://arxiv.org/pdf/1704.08006.pdf)
    - 오타
    - 어순 변경
    - 띄어쓰기 무시
- foolbox에 있는 generating adversarial sample(blurring, add noise, pixel 갈아끼우기 등) -> text 자료와는 좀 맞지가 않음
- 또한 기존의 text쪽 GAN 연구는 사람이 쓴 글과 기계가 쓴 글을 구분하게 하는게 목표였음.. 왜 사람이 가장 큰 적이라는 사실을 모르는걸까?
- Contribution
    - 적절한 adversarial sample 만드는 방법: 사람손 많이 안들이고 자동으로 만들 수 있는 기법들을 많이 찾는 것이 관건이 될 것 같은데...
        - 글자 갈아끼우기
        - 어순 바꾸기
        - 어... 음... 뭐 이런 쓸데없는 말 집어넣기?
        - 약어 및 일상어
    - 어떤 neural network structure가 이러한 adversarial attack에 robust할 것인가