### Title
A Neural Representation of Sketch Drawings
### Authors
David Ha, Douglas Eck

### link
[arxiv](https://arxiv.org/abs/1704.03477v1)

### Contents
이 논문은 사람들의 stroke를 모델링해서 그림그리는 것을 배우는 모형에 관한 것이다.

### 유의깊게 본 점
- 처음에는 당연히 cnn -> category -> 그림 재생성 이런 것일 줄 알았는데 그게 아니고 그냥 stroke 모형이었다는거. <br/>나는 이미지 쪽에는 별로 관심이 없어서 잘몰랐지만 이미 필기체 등 모형화할 때 이런 식으로 많이 접근하더라
- rnn cell에 들어가는 변수는 총 5개, 그 중 앞의 2개는 $delta$x, $delta$y로 펜 움직임 변수, 뒤의 세개는 1. 펜 긋는 상태, 2. 펜 종이에서 뗀 상태, 3. 그리기 끝
- conditional model에서는 단서?라고 해야하려나 여튼 다른 비슷한 그림을 encoding해서 집어넣음. bidirectional rnn 거치고 이걸 fnn에 통과시켜서 $mu$, $sigma$로 만든 다음 $mu$+e*$sigma$, e~N(0, I)로 변환. <br/> 이 z를 decoding 단계에서 stroke vector와 concatenating시켜서 새로운 input으로 집어넣음
- loss function은 두 가지로 나뉨. kl loss, reconstruction loss. reconstruction loss는 약간의 트릭이 들어가는데 이는 자료의 불균형때문(end state는 1번밖에 없어서 모델링이 안됨, weight준거 아니고 최대 길이 정하는 방식으로 했음)
- decoding rnn은 HyperLSTM 썼다는데 나 잘 모름. 이거 관련 논문 및 참고자료 보자 내일은
[논문](https://arxiv.org/pdf/1609.09106v1.pdf)
[참고자료](http://blog.otoro.net/2016/09/28/hyper-networks/)
- 300stroke 넘어가면 모델링이 잘 안된다고 하네
- variational autoencoder와 gan을 좀 비교해서 정리하는 시간 한 번은 가져야 할 듯
- 논문이 알록달록하고 그림이 많아서 좋다ㅎㅎ 