### Title
Improved Variational Inference with Inverse Autoregressive Flow

### Authors


### link
[Download link](http://de.arxiv.org/pdf/1606.04934.pdf)

### Contents
- vanilla vae 문제점 중 하나는 q(z|x)를 만들 때 순전히 계산 이득 / inference시의 이득을 위해 N(0, I)의 모양이 되게 했다는 점
- 이로 인해 실제라면 더 복잡한 p(z|x)를 완전히 따라가는게 힘들었음
- 이러한 문제를 극복하기 위해 나온 방법이 flow
    - bijector를 이용한 transformation으로 단순한 분포를 복잡한 분포로 만들 수 있음
    - z ~ f(f(f(...f(z_0)))), where z ~ N(0, I)
    - KL(q|p)가 0에 더 가까워지니까 lower bound가 실제로 우리가 배워야 하는 logp(X)에 더 가까워짐
- 그럼 이 논문에서는 뭘 한거냐?
    - 새로운 flow가 될 수 있는 transformation을 제안함
    - Inverse Autoregressive Flow(IAF)
- 어떤 장점이 있을까?
    - 기존에 제안되었던 normalizing flow는 엄청 단순한 transformation이었음
    - 복잡한 분포를 모사하기 위해서는 많은 step이 요구됨
    - IAF에서는 이런 단점이 해결되었다고 이야기하고 있음
        - 기본적으로는 autoregressive transformation임
        - z_t = mu_t + sigma_t * z_t-1
        - z_1 ~ z_t의 jacobian을 생각해보면 lower triangular matrix임
        - flow에서 변환 후 확률이 어떻게 되는지 알기 위해서는 jacobian 계산이 필요한데 lower triangular matrix는 이 계산이 쉬움
        - jacobian을 직접 계산하는건 너무 수고스러운 일인데 이걸 쉽게 해주니 좋은 방법
- jacobian 계산이 쉬운 transformation을 만드는게 vae에서 중요한 일 중 하나인 것 같은데 이 논문은 그걸 아주 깔쌈하게 해결함
- 다음에는 real NVP를 보고 어떤 차이점이 있는지 살펴보면 좋을 것 같음
- 그리고 하나 이해 안가는 구절이 있었는데... 나중에 물어보장